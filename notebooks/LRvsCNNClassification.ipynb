{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aCkmxIvo5Tyr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN Implementation for Text Classification\n",
        "Convolution Neural Network(CNN) is generally used for image classification which goes through every corner, vector and dimension of pixel matrix.\n",
        "\n",
        "We were unable to find related image dataset that can correlate to the entertainment dataset that we have chose.\n",
        "\n",
        "## Step 1 - Data Cleaning\n",
        "We have chosen the gaming dataset to do text classification on the reviews provided into positive and negatives.\n",
        "\n",
        "Understanding the data"
      ],
      "metadata": {
        "id": "wanY3nBI4vpG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "import numpy as np\n",
        "\n",
        "data = pd.read_csv('cleaned_game_dataset.csv')\n",
        "reviews = data['0']\n",
        "print(reviews.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZ9JbYHW5oxs",
        "outputId": "cac0c135-92b2-4c90-b993-3629a6a0bb8b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    The first playthrough of elden ring is one of ...\n",
            "1    a replay solidified my love for elden ring so ...\n",
            "2    The game is absolutely beautiful with so much ...\n",
            "3    Took everything great about the Soulsborne gam...\n",
            "4    I play with my overlevelled friend every time ...\n",
            "Name: 0, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2 - Creating Dataset\n",
        "In order to train the model we need to have a dataset with both labels and sentences. We have got the sentences after cleaning the dataset obtained from Kaggle. Now to classify the sentences into positive and negative we are gonna use the words present in the sentences to compare with the list of positive words and negative words that are taken from the mentioned github repository to classify it.\n",
        "\n",
        "We will be using this classified dataset to train Logistic Regression model and Convolution Neural Network Model. The results of these two models will be compared and analyzed. We will also be doing some hyperparameter tuning for the CNN model to yield better results than LR if required.\n"
      ],
      "metadata": {
        "id": "lFUqNiIT6p4b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "positive_list = []\n",
        "with open('positive-words.txt', 'r') as file:\n",
        "    positive_list = file.read().splitlines()\n",
        "postive_keys = set(positive_list)\n",
        "\n",
        "negative_list = []\n",
        "with open('negative-words.txt', 'r') as file:\n",
        "    negative_list = file.read().splitlines()\n",
        "negative_keys = set(negative_list)\n",
        "\n",
        "confused_dataset = []\n",
        "sorted_dataset = []\n",
        "\n",
        "review_flag = 0\n",
        "positive_flag = 0\n",
        "negative_flag = 0\n",
        "confused_flag = 0\n",
        "for review in reviews:\n",
        "  pos = any(ele in review for ele in positive_list)\n",
        "  neg = any(negele in review for negele in negative_list)\n",
        "  if((pos == False and neg == False)):\n",
        "    continue\n",
        "  if(pos == True and neg == False):\n",
        "    review_flag = 1\n",
        "    positive_flag += 1\n",
        "  if (pos == False and neg == True):\n",
        "    review_flag = 0\n",
        "    negative_flag += 1\n",
        "  if (pos == True and neg == True):\n",
        "    pos_values = [review.count(key) for key in postive_keys]\n",
        "    neg_values = [review.count(key) for key in negative_keys]\n",
        "    avg = sum(pos_values) - sum(neg_values)\n",
        "    if(avg > 0):\n",
        "        review_flag = 1\n",
        "        positive_flag += 1\n",
        "    if(avg < 0):\n",
        "        review_flag = 0\n",
        "        negative_flag += 1\n",
        "    if(avg == 0):\n",
        "        confused_dataset.append([review, -1])\n",
        "        continue\n",
        "  sorted_dataset.append([review, review_flag])\n",
        "\n",
        "with open('sorted_games.csv', 'w', encoding='UTF-8', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerows(sorted_dataset)\n",
        "\n",
        "with open('confused_data.csv', 'w', encoding='UTF-8', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerows(confused_dataset)\n",
        "\n",
        "print(sorted_dataset[0])\n",
        "print(confused_dataset[0])\n",
        "print(f\"positive reviews count: {positive_flag} negative reviews count: {negative_flag}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ujydVvy8WtR",
        "outputId": "2f9448d3-539e-4e62-d275-ff237968ba83"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['The first playthrough of elden ring is one of the best eperiences gaming can offer you but after youve explored everything in the open world and you ve experienced all of the surprises you lose motivation to go exploring on repeat playthroughs which takes lot away from the replayability which is very important thing for from games imo ', 0]\n",
            "['People tell me this game gets really really good at some point but ve beaten entire games in the amount of time gave this game ', -1]\n",
            "positive reviews count: 1278 negative reviews count: 1301\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After sorting the dataset we can see that we have equal amount of positive and negative reviews. We will be using these to train and test the LR model against CNN model.\n",
        "\n",
        "We also created a confused dataset which will be manually sorted and be used for testing against both the LR model and CNN Model.\n",
        "\n",
        "## Step 3 - Training the Model\n",
        "We will now be using the data created above and split it into test and train to create a Logistic Regression model for classification and Convolution Neural Network model and compare the results of both."
      ],
      "metadata": {
        "id": "ZoE-5k4g-tM-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FsFT59dYQYvC",
        "outputId": "f157cbae-c601-4860-95a4-432a4a282f03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8888888888888888\n",
            "Manual Data Accuracy: 0.5142857142857142\n",
            "Unique gameplay encounters and cool setting make this one of the better mgs titles in the series What thrill \n",
            "[176, 42, 1078, 2, 107, 379, 115, 8, 30, 3, 1, 81, 2628, 475, 11, 1, 77, 65, 2629]\n",
            "[ 38 322 211   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0]\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 100, 200)          1520600   \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 96, 256)           256256    \n",
            "                                                                 \n",
            " global_max_pooling1d (Glob  (None, 256)               0         \n",
            " alMaxPooling1D)                                                 \n",
            "                                                                 \n",
            " dense (Dense)               (None, 15)                3855      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 16        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1780727 (6.79 MB)\n",
            "Trainable params: 1780727 (6.79 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Training Accuracy: 0.9989\n",
            "Testing Accuracy:  0.8747\n",
            "Manual Testing Accuracy:  0.5429\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "import numpy as np\n",
        "\n",
        "data = pd.read_csv('sorted_games.csv', names=['sentence', 'label'])\n",
        "test_data = pd.read_csv('confused_data.csv', names=['sentence', 'label'])\n",
        "#print(data)\n",
        "review = data['sentence'].values\n",
        "label = data['label'].values\n",
        "# split data into test and train\n",
        "review_train, review_test, label_train, label_test = train_test_split(review, label, test_size=0.30, random_state=2000)\n",
        "\n",
        "manual_test_sent = test_data['sentence'].values\n",
        "manual_test_lab = test_data['label'].values\n",
        "\n",
        "review_vectorizer = CountVectorizer()\n",
        "review_vectorizer.fit(review_train)\n",
        "Xlr_train = review_vectorizer.transform(review_train)\n",
        "Xlr_test = review_vectorizer.transform(review_test)\n",
        "Xlr_train\n",
        "LRmodel = LogisticRegression()\n",
        "LRmodel.fit(Xlr_train, label_train)\n",
        "score = LRmodel.score(Xlr_test, label_test)\n",
        "xlr_test_data = review_vectorizer.transform(manual_test_sent)\n",
        "manual_score = LRmodel.score(xlr_test_data, manual_test_lab)\n",
        "print(\"Accuracy:\", score)\n",
        "print(\"Manual Data Accuracy:\", manual_score)\n",
        "\n",
        "#CNN Implementation\n",
        "\n",
        "\n",
        "\n",
        "tokenizer = Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(review_train)\n",
        "Xcnn_train = tokenizer.texts_to_sequences(review_train)\n",
        "Xcnn_test = tokenizer.texts_to_sequences(review_test)\n",
        "Xcnn_test_data = tokenizer.texts_to_sequences(manual_test_sent)\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print(review_train[1])\n",
        "print(Xcnn_train[1])\n",
        "maxlen = 100\n",
        "Xcnn_train = pad_sequences(Xcnn_train, padding='post', maxlen=maxlen)\n",
        "Xcnn_test = pad_sequences(Xcnn_test, padding='post', maxlen=maxlen)\n",
        "Xcnn_test_data = pad_sequences(Xcnn_test_data, padding='post', maxlen=maxlen)\n",
        "print(Xcnn_train[0, :])\n",
        "embedding_dim = 200\n",
        "textcnnmodel = Sequential()\n",
        "textcnnmodel.add(layers.Embedding(vocab_size, embedding_dim, input_length=maxlen))\n",
        "textcnnmodel.add(layers.Conv1D(256, 5, activation='relu'))\n",
        "textcnnmodel.add(layers.GlobalMaxPooling1D())\n",
        "textcnnmodel.add(layers.Dense(15, activation='relu'))\n",
        "textcnnmodel.add(layers.Dense(1, activation='sigmoid'))\n",
        "textcnnmodel.compile(optimizer='adam',\n",
        "               loss='binary_crossentropy',\n",
        "               metrics=['accuracy'])\n",
        "textcnnmodel.summary()\n",
        "\n",
        "textcnnmodel.fit(Xcnn_train, label_train,\n",
        "                     epochs=50,\n",
        "                     verbose=False,\n",
        "                     validation_data=(Xcnn_test, label_test),\n",
        "                     batch_size=20)\n",
        "loss, accuracy = textcnnmodel.evaluate(Xcnn_train, label_train, verbose=False)\n",
        "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
        "loss, accuracy = textcnnmodel.evaluate(Xcnn_test, label_test, verbose=False)\n",
        "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))\n",
        "loss, accuracy = textcnnmodel.evaluate(Xcnn_test_data, manual_test_lab, verbose=False)\n",
        "print(\"Manual Testing Accuracy:  {:.4f}\".format(accuracy))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above we can see that the test results of Logistic Regression is better than CNN model. However, running the test on the dataset created/classified manually the CNN performs better than LR. This might be due to various reasons but also mainly due to the hyperparameter tuning with the CNN. The results of different hyperparameters are discussed and shown in the readme of the project."
      ],
      "metadata": {
        "id": "WB-0bu_IAvk-"
      }
    }
  ]
}